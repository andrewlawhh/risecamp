{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Hyperparameter optimization for machine learning\n",
    "\n",
    "Many machine learning models have hyperparamters -- parameters that control some aspect of the model. The exact setting of these hyperparameters can dramatically impact the performance of your underlying model. Fortunately, most hyperparameters can be tried in parallel, making the task of *hyperparemter optimization* a great fit for PyWren. \n",
    "\n",
    "Here we use a simple dataset included in scikit-learn to show how to do hyperparameter optimization across a number of different datasets, and a number of different cross-validations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T18:42:54.299642Z",
     "start_time": "2017-08-31T18:42:53.957799Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pywren\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.svm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:14:57.411420Z",
     "start_time": "2017-09-03T22:14:57.406030Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# get the data\n",
    "\n",
    "First we load in the data from scikit learn and examine it. Here we will be using an existing dataset of breast cancer tumor properties that's shipped with scikit-learn. This is a small binary classification problem, and the hyperparameter optimization we are doing here is reletively trivial. Hopefully this will inspire good ideas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T18:41:50.229834Z",
     "start_time": "2017-08-31T18:41:49.818438Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset from scikit learn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "bc = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Let's explore properties of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:16:46.932962Z",
     "start_time": "2017-09-03T22:16:46.926851Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(bc['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "The data is in the `data` key and the classification label is in the `target` key. Load those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:17:48.449681Z",
     "start_time": "2017-09-03T22:17:48.443980Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# load the data as X and y\n",
    "X = bc['data']\n",
    "y = bc['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "First we explore generic prediction on the dataset with an off-the-shelf classifier. We use a scikit-learn pipeline which does the following:\n",
    "\n",
    "1. standardize each input feature to zero-mean unit variance \n",
    "2. Apply a SVM with a given set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T18:42:55.649545Z",
     "start_time": "2017-08-31T18:42:55.587170Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a train/test split for cross-validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# construct a scikit learn pipeline which normalizes\n",
    "# the data and then runs a SVM \n",
    "\n",
    "p = Pipeline(steps=[('standardize', StandardScaler()), \n",
    "                    ('learn', sklearn.svm.SVC(C=0.1, kernel='poly', degree=3))])\n",
    "\n",
    "\n",
    "# fit the data\n",
    "p.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Then we can evaluate the behavior of the classifier on the held-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:19:06.923411Z",
     "start_time": "2017-09-03T22:19:06.904985Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# predict the held-out data\n",
    "pred = p.predict(X_test)\n",
    "\n",
    "# measure the accuracy\n",
    "sklearn.metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# use PyWren to try many HP values\n",
    "\n",
    "Now we try for many folds and many hyperparameters with pywren. We can also try many different folds to get confidence intervals on the sensitivyt of our new estimator. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:19:53.941948Z",
     "start_time": "2017-09-03T22:19:53.118858Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# now we can train lots of models! and get error bars! \n",
    "\n",
    "def train_model(args):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # extract the args\n",
    "    (X_train, X_test, y_train, y_test), hps = args\n",
    "    \n",
    "    import sklearn.svm \n",
    "    \n",
    "    # create the pipeline\n",
    "    p = Pipeline(steps=[('standardize', StandardScaler()), \n",
    "                        ('learn', sklearn.svm.SVC(**hps))])\n",
    "    \n",
    "    # fit\n",
    "    p.fit(X_train, y_train)\n",
    "    return p\n",
    "\n",
    "\n",
    "wrenexec = pywren.default_executor()\n",
    "\n",
    "\n",
    "FOLD_N = 10 # number of cross-validation sets\n",
    "\n",
    "cv_sets = []\n",
    "for i in range(FOLD_N):\n",
    "    cv_sets.append(train_test_split(\n",
    "                     X, y, test_size=0.4, random_state=i))\n",
    "\n",
    "# set of SVM hyperparameters we want to try\n",
    "hps =  [dict(C=10.0, kernel='rbf', degree=3), \n",
    "        dict(C=1.0, kernel='rbf', degree=3),\n",
    "        dict(C=0.1, kernel='rbf', degree=3)]\n",
    "\n",
    "\n",
    "# combine them all using itertools\n",
    "args = list(itertools.product(cv_sets, hps) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:20:24.062138Z",
     "start_time": "2017-09-03T22:19:54.885261Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# perform the map                   \n",
    "futures = wrenexec.map(train_model, args)\n",
    "results = pywren.get_all_results(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T18:53:08.174061Z",
     "start_time": "2017-08-31T18:53:08.167526Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Analyzing the results\n",
    "\n",
    "We construct a dataframe of the results to facilitate subsequent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:21:57.967603Z",
     "start_time": "2017-09-03T22:21:57.835333Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# construct a dataframe using the resulting models to predict accuracy on their held-out dataset\n",
    "res = []\n",
    "for m, ((X_train, X_test, y_train, y_test), hps) in zip(results, args):\n",
    "    pred = m.predict(X_test)\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, pred)\n",
    "    hp_row = hps.copy()\n",
    "    hp_row['accuracy'] = acc\n",
    "    res.append(hp_row)\n",
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T18:53:40.177537Z",
     "start_time": "2017-08-31T18:53:40.173478Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### we use seaborn to plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:22:01.951148Z",
     "start_time": "2017-09-03T22:22:01.642755Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='C', y='accuracy', data=df)\n",
    "sns.stripplot(x='C', y='accuracy', data=df, color='k', jitter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise: Try different classifiers\n",
    "\n",
    "Many different classifiers can work for the simple binary classification problem. We encourage you to try several from scikit learn below. Perhaps logistic regression or a random forest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:51:43.297868Z",
     "start_time": "2017-09-03T22:51:42.484352Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# now we can train lots of models! and get error bars! \n",
    "\n",
    "def train_model(args):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # extract the args\n",
    "    (X_train, X_test, y_train, y_test), (classifier_name, hps) = args\n",
    "    \n",
    "    import sklearn.svm \n",
    "    import sklearn.ensemble\n",
    "    \n",
    "    # create the pipeline\n",
    "    if classifier_name == \"svm\":\n",
    "        p = Pipeline(steps=[('standardize', StandardScaler()), \n",
    "                            ('learn', sklearn.svm.SVC(**hps))])\n",
    "    elif classifier_name == \"myclassifierPipeline\":\n",
    "        # TODO CREATE YOUR PIPELINE HERE\n",
    "        #\n",
    "    ## TODO ADD MORE \n",
    "    \n",
    "    # fit\n",
    "    p.fit(X_train, y_train)\n",
    "    return p\n",
    "\n",
    "\n",
    "wrenexec = pywren.default_executor()\n",
    "\n",
    "\n",
    "FOLD_N = 4 # number of cross-validation sets\n",
    "\n",
    "cv_sets = []\n",
    "for i in range(FOLD_N):\n",
    "    cv_sets.append(train_test_split(\n",
    "                     X, y, test_size=0.4, random_state=i))\n",
    "\n",
    "# set of SVM hyperparameters we want to try\n",
    "models_and_hps =  [('svm', dict(C=10.0, kernel='rbf', degree=3)), \n",
    "                   ('svm', dict(C=1.0, kernel='rbf', degree=3)),\n",
    "                   ('svm', dict(C=0.1, kernel='rbf', degree=3)),\n",
    "                   # Add additional configurations and \n",
    "                  ]\n",
    "\n",
    "\n",
    "# combine them all using itertools\n",
    "args = list(itertools.product(cv_sets, models_and_hps) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:52:14.339999Z",
     "start_time": "2017-09-03T22:51:48.738799Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# perform the map  \n",
    "## TODO call pywren and get the results\n",
    "import sklearn.ensemble.forest\n",
    "futures = wrenexec.map(train_model, args)\n",
    "results = pywren.get_all_results(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:52:40.591344Z",
     "start_time": "2017-09-03T22:52:40.456759Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# construct a dataframe using the resulting models to predict accuracy on their held-out dataset\n",
    "res = []\n",
    "for m, ((X_train, X_test, y_train, y_test), (model_name, hps)) in zip(results, args):\n",
    "    pred = m.predict(X_test)\n",
    "    acc = sklearn.metrics.accuracy_score(y_test, pred)\n",
    "    hp_row = hps.copy()\n",
    "    hp_row['accuracy'] = acc\n",
    "    hp_row['hp_str'] = str(hps)\n",
    "    hp_row['model_name'] = model_name\n",
    "    res.append(hp_row)\n",
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T22:52:42.226052Z",
     "start_time": "2017-09-03T22:52:41.640660Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='model_name', y='accuracy', data=df, hue=\"hp_str\")\n",
    "#sns.stripplot(x='C', y='accuracy', data=df, color='k', jitter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# additional things to try\n",
    "\n",
    "Some additional recommended exercises:\n",
    "1. Scikit-learn has several other datasets you might try?\n",
    "2. are there other metrics such as `ROC` that might be a better indicator of performance? \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
