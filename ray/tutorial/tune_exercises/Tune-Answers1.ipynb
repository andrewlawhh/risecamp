{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tune.png\" alt=\"Tune Logo\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune is a scalable framework for model training and hyperparameter search with a focus on deep learning and deep reinforcement learning.\n",
    "\n",
    "**Code**: https://github.com/ray-project/ray/tree/master/python/ray/tune\n",
    "\n",
    "**Examples**: https://github.com/ray-project/ray/tree/master/python/ray/tune/examples\n",
    "\n",
    "**Documentation**: http://ray.readthedocs.io/en/latest/tune.html\n",
    "\n",
    "**Mailing List** https://groups.google.com/forum/#!forum/ray-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Tuning hyperparameters is often the most expensive part of the machine learning workflow. Tune is built to , demonstrating an efficient and scalable solution for this pain point.\n",
    "\n",
    "\n",
    "## Outline\n",
    "This tutorial will walk you through the following process:\n",
    "\n",
    "1. Creating and training a model on a toy dataset (MNIST)\n",
    "2. Integrating Tune into your workflow\n",
    "3. Trying out advanced features - plugging in an efficient scheduler and search algorithm\n",
    "4. Validating your trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "% matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Creating a model to be trained.\n",
    "\n",
    "Let's create a Convolutional Neural Network model that will classify digits (MNIST).\n",
    "\n",
    "<img src=\"mnist.png\" alt=\"MNIST Visualization\" width=\"400\"/>\n",
    "\n",
    "This is a fairly simple dataset, but it enables us to explore Tune's functionality in depth.\n",
    "We will use 60,000 images to train the network. The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the digit the image represents.\n",
    "\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "1. Feed the training data to the modelâ€”in this example, the train_images and train_labels arrays.\n",
    "2. The model learns to associate images and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints:\n",
    "1. `data_generator` yields (`data_batch`, `label_batch`).\n",
    "2. You can use `model.fit(data, labels)` to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Keras MNIST Example')\n",
    "parser.add_argument('--lr', type=float, default=0.1, help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.0, help='SGD momentum')\n",
    "parser.add_argument('--kernel1', type=int, default=3, help='Size of first kernel')\n",
    "parser.add_argument('--kernel2', type=int, default=3, help='Size of second kernel')\n",
    "parser.add_argument('--poolsize', type=int, default=2, help='Size of Poolin')\n",
    "parser.add_argument('--dropout1', type=float, default=0.25, help='Size of first kernel')\n",
    "parser.add_argument('--hidden', type=int, default=16, help='Size of Hidden Layer')\n",
    "parser.add_argument('--dropout2', type=float, default=0.5, help='Size of first kernel')\n",
    "\n",
    "DEFAULT_ARGS = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(parameters):\n",
    "    config = DEFAULT_ARGS.copy()  # This is obtained via the global scope\n",
    "    config.update(parameters)\n",
    "    num_classes = 10\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(config[\"kernel1\"], config[\"kernel1\"]),\n",
    "                     activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(64, (config[\"kernel2\"], config[\"kernel2\"]), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(config[\"poolsize\"], config[\"poolsize\"])))\n",
    "    model.add(Dropout(config[\"dropout1\"]))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(config[\"hidden\"], activation='relu'))\n",
    "    model.add(Dropout(config[\"dropout2\"]))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(\n",
    "                      lr=config[\"lr\"], momentum=config[\"momentum\"]),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_mnist(args):\n",
    "    \"\"\"Loads data, does one pass over the data, and saves the weights.\"\"\"\n",
    "    data_generator = load_data()\n",
    "    model = make_model(args)\n",
    "    for x_batch, y_batch in data_generator:\n",
    "        model.fit(x_batch, y_batch)\n",
    "    model.save_weights(\"./weights.h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll specify some arguments and some reasonable defaults for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Then*, we want to train this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_mnist(DEFAULT_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now quickly try out this model to see if it works as expected (tip: don't expect it to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = make_model(DEFAULT_ARGS)\n",
    "first_model.load_weights(\"./weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    prepared_data = prepare_data(data)\n",
    "    first_model.predict(prepared_data).argmax()\n",
    "except Exception: # run through only\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Setting up Tune\n",
    "\n",
    "One thing we might want to do now is find better hyperparameters so that our model trains more quickly. Let's make some minor modifications to utilize Tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune uses Ray as a backend, so we will first import and initialize Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune will automate and distribute your hyperparameter search by scheduling a number of trials in a cluster. Each trial runs a user-defined Python function with a given set of hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two steps to use Tune:\n",
    "\n",
    "*1*. For the function you wish to tune, we need to change the signature to a specific format as shown below. Specifically: pass in a **``reporter``** object to the below `train_mnist_tune` class.\n",
    "\n",
    "```python\n",
    "def trainable(config, reporter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        config (dict): Parameters provided from the search algorithm\n",
    "            or variant generation.\n",
    "        reporter (Reporter): Handle to report intermediate metrics to Tune.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "*2*. We want to keep track of performance as the model is training. Specifically: get the `mean_accuracy` from Keras, and call the **``reporter``** to report the `mean_accuracy` for every batch. You can get model accuracy from Keras with the following code:\n",
    "\n",
    "```python\n",
    "result = model.fit(x_batch, y_batch, verbose=0)\n",
    "mean_accuracy = result.history[\"acc\"][0]\n",
    "```\n",
    "\n",
    "\n",
    "Example of using the reporter:\n",
    "\n",
    "```python\n",
    " def train_func(config, reporter):  # add a reporter arg\n",
    "     ...\n",
    "     for data, target in dataset:\n",
    "         accuracy = model.fit(data, target)\n",
    "         reporter(mean_accuracy=accuracy) # report metrics\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Change this signature #####\n",
    "def train_mnist_tune(config, reporter):\n",
    "    data_generator = load_data()\n",
    "    model = make_model(config)\n",
    "    for x_batch, y_batch in data_generator:\n",
    "        result = model.fit(x_batch, y_batch, verbose=0)\n",
    "        reporter(mean_accuracy=result.history[\"acc\"][0])\n",
    "        # TODO: Use the reporter here to fill out intermediate metrics\n",
    "        ##########\n",
    "    model.save_weights(\"./weights_tune.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now try to search over the learning rate. \n",
    "\n",
    "*NOTE: You can find the documentation for this section here: https://ray.readthedocs.io/en/latest/tune-usage.html#specifying-experiments*\n",
    "\n",
    "\n",
    "Let's **first create a Tune Experiment specification**. The relevant documentation for the Experiment class is here:\n",
    "\n",
    "```python\n",
    "class ray.tune.Experiment(name, run, stop=None, config=None, ... ):\n",
    "    \"\"\"Tracks experiment specifications.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): Name of experiment.\n",
    "        run (function|class|str): The algorithm or model to train.\n",
    "            This may refer to the name of a built-on algorithm\n",
    "            (e.g. RLLib's DQN or PPO), a user-defined trainable\n",
    "            function or class, or the string identifier of a\n",
    "            trainable function or class registered in the tune registry.\n",
    "        stop (dict): The stopping criteria. The keys may be any field in\n",
    "            the return result of 'train()', whichever is reached first.\n",
    "            Defaults to empty dict.\n",
    "        config (dict): Algorithm-specific configuration for Tune variant\n",
    "            generation (e.g. env, hyperparams). Defaults to empty dict.\n",
    "            Custom search algorithms may ignore this.\n",
    "```\n",
    "\n",
    "1. Set the stopping criteria to stop when `mean_accuracy` passes `0.95`.\n",
    "\n",
    "\n",
    "We also want to designate a search space. **Randomly search for learning rate between 0.001 to 0.1, and do a grid search over `momentum` for `[0.2, 0.4, 0.6]` **(https://ray.readthedocs.io/en/latest/tune-usage.html#tune-search-space-default)\n",
    "\n",
    "You can use `tune.grid_search` to specify an axis of a grid search. By default, Tune also supports sampling parameters from user-specified lambda functions, which can be used independently or in combination with grid search.\n",
    "\n",
    "The following example shows grid search over two nested parameters combined with random sampling from a lambda functions, generating 9 different trials. \n",
    "\n",
    "```python\n",
    "config={\n",
    "    \"alpha\": lambda spec: np.random.uniform(100),\n",
    "    \"nn_layers\": [\n",
    "         tune.grid_search([16, 64, 256]),\n",
    "         tune.grid_search([16, 64, 256]),\n",
    "    ],\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = tune.Experiment(\n",
    "    \"experiment_name\",\n",
    "    run=train_mnist_tune,\n",
    "    trial_resources={\"cpu\": 4},\n",
    "    stop={\"mean_accuracy\": 0.95},\n",
    "    config={\"lr\": lambda spec: np.random.uniform(0.001, 0.1),\n",
    "            \"momentum\": tune.grid_search([0.2, 0.4, 0.6])}\n",
    ")\n",
    "\n",
    "assert configuration.spec.get(\"stop\", {}).get(\"mean_accuracy\") == 0.95\n",
    "assert \"grid_search\" in configuration.spec.get(\"config\", {}).get(\"momentum\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = tune.run_experiments(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best result is\", get_best_result(trials, metric=\"mean_accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using a scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use this machine to multiplex our training to find the best parameters using a single machine.\n",
    "\n",
    "1. Run 10 samples (https://ray.readthedocs.io/en/latest/tune-usage.html#sampling-multiple-times)\n",
    "2. Create an Asynchronous HyperBand Scheduler (https://ray.readthedocs.io/en/latest/tune-schedulers.html#asynchronous-hyperband). The documentation is shown below. \n",
    "\n",
    "Be sure to set the `time_attr` to `training_iteration` and `reward_attr` to `mean_accuracy`.\n",
    "\n",
    "```python\n",
    "class AsyncHyperBandScheduler(FIFOScheduler):\n",
    "    \"\"\"Implements the Async Successive Halving.\n",
    "\n",
    "    See https://openreview.net/forum?id=S1Y7OOlRZ\n",
    "\n",
    "    Args:\n",
    "        time_attr (str): A training result attr to use for comparing time.\n",
    "            Note that you can pass in something non-temporal such as\n",
    "            `training_iteration` as a measure of progress, the only requirement\n",
    "            is that the attribute should increase monotonically.\n",
    "        reward_attr (str): The training result objective value attribute. As\n",
    "            with `time_attr`, this may refer to any objective value. Stopping\n",
    "            procedures will use this attribute.\n",
    "        ...\n",
    "        \n",
    "    Examples:\n",
    "        >>> hyperband = AsyncHyperBandScheduler(\n",
    "        >>>     time_attr='training_iteration',\n",
    "        >>>     reward_attr='mean_accuracy')\n",
    "    \"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "## TODO: Create an Asynchronous HyperBand Scheduler\n",
    "hyperband = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\",\n",
    "    reward_attr=\"mean_accuracy\")\n",
    "configuration.spec[\"num_samples\"] = 10  # set this to 10\n",
    "# configuration.spec[\"config\"] = {\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the previous configuration, pass in the HyperBand scheduler to `run_experiments`.\n",
    "\n",
    "Recall that the `run_experiments` API is:\n",
    "```python\n",
    "def run_experiments(experiments=None,\n",
    "                    search_alg=None,\n",
    "                    scheduler=None,\n",
    "                    ...):\n",
    "    \"\"\"Runs and blocks until all trials finish.\n",
    "\n",
    "    Args:\n",
    "        experiments (Experiment | list | dict): Experiments to run. Will be\n",
    "            passed to `search_alg` via `add_configurations`.\n",
    "        search_alg (SearchAlgorithm): Search Algorithm. Defaults to\n",
    "            BasicVariantGenerator.\n",
    "        scheduler (TrialScheduler): Scheduler for executing\n",
    "            the experiment. Choose among FIFO (default), MedianStopping,\n",
    "            AsyncHyperBand, and HyperBand.\n",
    "        ...\n",
    "    \n",
    "    Returns:\n",
    "        List of Trial objects, holding data for each executed trial.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call `run_experiments`\n",
    "trials = tune.run_experiments(configuration, scheduler=hyperband)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = get_best_model(make_model, trials, metric=\"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data, validation_labels = load_validation()\n",
    "best_model.evaluate(validation_data, validation_labels)\n",
    "\n",
    "first_model.evaluate(validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out your model on some manual inputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(open(\"input_final.html\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    manual_input = prepare_data(final_data)\n",
    "    best = best_model.predict(manual_input).argmax()\n",
    "    first = first_model.predict(manual_input).argmax()\n",
    "\n",
    "    print(\"Best model got {}, first model got {}\".format(best, first))\n",
    "except Exception:\n",
    "    print(\"skipping input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Try using a search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune is an execution layer, so we can combine powerful optimizers such as HyperOpt (https://github.com/hyperopt/hyperopt) with state-of-the-art algorithms such as HyperBand without modifying any model training code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "1. Create a HyperOptSearch object and run an experiment combining both the previously created `hyperband` scheduler and this Search algorithm. Use the given search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from ray.tune.suggest import HyperOptSearch\n",
    "\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.uniform(\"lr\", 0.001, 0.1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"hidden\": hp.choice(\"hidden\", np.arange(16, 256, dtype=int)),\n",
    "    \"dropout1\": hp.uniform(\"dropout1\", 0.2, 0.8),\n",
    "}\n",
    "\n",
    "## TODO: CREATE A HyperOptObject\n",
    "hyperopt_search = HyperOptSearch(space, reward_attr=\"mean_accuracy\")\n",
    "\n",
    "## TODO: Pass in the object to Tune.\n",
    "tune.run_experiments(\n",
    "    configuration, search_alg=hyperopt_search, scheduler=hyperband)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
