{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tune.png\" alt=\"Tune Logo\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune is a scalable framework for model training and hyperparameter search with a focus on deep learning and deep reinforcement learning.\n",
    "\n",
    "**Code**: https://github.com/ray-project/ray/tree/master/python/ray/tune\n",
    "\n",
    "**Examples**: https://github.com/ray-project/ray/tree/master/python/ray/tune/examples\n",
    "\n",
    "**Documentation**: http://ray.readthedocs.io/en/latest/tune.html\n",
    "\n",
    "**Mailing List** https://groups.google.com/forum/#!forum/ray-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Tuning hyperparameters is often the most expensive part of the machine learning workflow. Tune is built to , demonstrating an efficient and scalable solution for this pain point.\n",
    "\n",
    "\n",
    "## Outline\n",
    "This tutorial will walk you through the following process:\n",
    "\n",
    "1. Creating and training a model on a toy dataset (MNIST)\n",
    "2. Integrating Tune into your workflow\n",
    "3. Trying out advanced features - plugging in an efficient scheduler and search algorithm\n",
    "4. Validating your trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "% matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Creating a model to be trained.\n",
    "\n",
    "Let's create a Convolutional Neural Network model that will classify digits (MNIST).\n",
    "\n",
    "<img src=\"mnist.png\" alt=\"MNIST Visualization\" width=\"400\"/>\n",
    "\n",
    "This is a fairly simple dataset, but it enables us to explore Tune's functionality in depth.\n",
    "We will use 60,000 images to train the network. The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the digit the image represents.\n",
    "\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "1. Feed the training data to the modelâ€”in this example, the `batch_of_data` and `batch_of_labels` arrays.\n",
    "2. The model learns to associate images and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll specify some arguments and some reasonable defaults for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Keras MNIST Example')\n",
    "parser.add_argument('--lr', type=float, default=0.1, help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.0, help='SGD momentum')\n",
    "parser.add_argument('--kernel1', type=int, default=3, help='Size of first kernel')\n",
    "parser.add_argument('--kernel2', type=int, default=3, help='Size of second kernel')\n",
    "parser.add_argument('--poolsize', type=int, default=2, help='Size of Poolin')\n",
    "parser.add_argument('--dropout1', type=float, default=0.25, help='Size of first kernel')\n",
    "parser.add_argument('--hidden', type=int, default=16, help='Size of Hidden Layer')\n",
    "parser.add_argument('--dropout2', type=float, default=0.5, help='Size of first kernel')\n",
    "\n",
    "DEFAULT_ARGS = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(parameters):\n",
    "    config = DEFAULT_ARGS.copy()  # This is obtained via the global scope\n",
    "    config.update(parameters)\n",
    "    num_classes = 10\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(config[\"kernel1\"], config[\"kernel1\"]),\n",
    "                     activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(64, (config[\"kernel2\"], config[\"kernel2\"]), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(config[\"poolsize\"], config[\"poolsize\"])))\n",
    "    model.add(Dropout(config[\"dropout1\"]))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(config[\"hidden\"], activation='relu'))\n",
    "    model.add(Dropout(config[\"dropout2\"]))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(\n",
    "                      lr=config[\"lr\"], momentum=config[\"momentum\"]),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Setup a basic model training script.\n",
    "Hints:\n",
    "1. `data_generator` is an iterator that returns (`batch_of_data`, `batch_of_labels`), like follows:\n",
    "\n",
    "```python\n",
    "for batch_of_data, batch_of_labels in data_generator:\n",
    "    do_something_interesting()\n",
    "```\n",
    "2. You can use `model.fit(batch_of_data, batch_of_labels)` to repeatedly improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(args):\n",
    "    \"\"\"Loads data, does one pass over the data, and saves the weights.\"\"\"\n",
    "    data_generator = load_data()\n",
    "    model = make_model(args)\n",
    "    ## TODO: use the `data_generator` to iterate over the data and improve the model\n",
    "    model.save_weights(\"./weights.h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this above training script to make sure things work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_mnist(DEFAULT_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now quickly try out this model to see if it works as expected (tip: don't expect it to). We'll load the model with our trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = make_model(DEFAULT_ARGS)\n",
    "first_model.load_weights(\"./weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, try to write a digit into the box below. This will automatically save your input in a variable `data` behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = prepare_data(data)\n",
    "print(\"This model predicted your input as\", first_model.predict(prepared_data).argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Setting up Tune\n",
    "\n",
    "One thing we might want to do now is find better hyperparameters so that our model trains more quickly and possibly to a higher accuracy. Let's make some minor modifications to utilize Tune. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune uses Ray as a backend, so we will first import and initialize Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune will automate and distribute your hyperparameter search by scheduling a number of **trials** on a machine. Each trial runs a user-defined Python function with a sampled set of hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Two steps to use Tune:\n",
    "\n",
    "1. For the function you wish to tune, we need to change the signature to a specific format as shown below. Specifically: **pass in a ``reporter`` object to the below `train_mnist_tune` class**.\n",
    "\n",
    "```python\n",
    "def trainable(config, reporter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        config (dict): Parameters provided from the search algorithm\n",
    "            or variant generation.\n",
    "        reporter (Reporter): Handle to report intermediate metrics to Tune.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "2. We want to keep track of performance as the model is training. Specifically: **get the `mean_accuracy` from Keras, and call the ``reporter`` to report the `mean_accuracy` for every batch**. \n",
    "\n",
    "You can get model accuracy from Keras with the following code:\n",
    "\n",
    "```python\n",
    "result = model.fit(x_batch, y_batch, verbose=0)\n",
    "mean_accuracy = result.history[\"acc\"][0]\n",
    "```\n",
    "\n",
    "\n",
    "Example of using the reporter:\n",
    "\n",
    "```python\n",
    " def train_func(config, reporter):  # add a reporter arg\n",
    "     ...\n",
    "     for data, target in dataset:\n",
    "         accuracy = model.fit(data, target)\n",
    "         reporter(mean_accuracy=accuracy) # report metrics\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_tune(config): ### TODO: Change this function signature following step 1 #####\n",
    "    data_generator = load_data()\n",
    "    model = make_model(config)\n",
    "    for x_batch, y_batch in data_generator:\n",
    "        result = model.fit(x_batch, y_batch, verbose=0)\n",
    "        ### TODO: Use the reporter here to fill out intermediate metrics following step 2###\n",
    "    ### Don't change the below    \n",
    "    model.save_weights(\"./weights_tune.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Let's now try to search over the learning rate. \n",
    "\n",
    "*NOTE: You can find the documentation for this section here: https://ray.readthedocs.io/en/latest/tune-usage.html#specifying-experiments*\n",
    "\n",
    "\n",
    "Let's first create a Tune Experiment specification. The relevant documentation for the Experiment class is here:\n",
    "\n",
    "```python\n",
    "class ray.tune.Experiment(name, run, stop=None, config=None, ... ):\n",
    "    \"\"\"Tracks experiment specifications.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): Name of experiment.\n",
    "        run (function|class|str): The algorithm or model to train.\n",
    "            This may refer to the name of a built-on algorithm\n",
    "            (e.g. RLLib's DQN or PPO), a user-defined trainable\n",
    "            function or class, or the string identifier of a\n",
    "            trainable function or class registered in the tune registry.\n",
    "        stop (dict): The stopping criteria. The keys may be any field in\n",
    "            the return result of 'train()', whichever is reached first.\n",
    "            Defaults to empty dict.\n",
    "        config (dict): Algorithm-specific configuration for Tune variant\n",
    "            generation (e.g. env, hyperparams). Defaults to empty dict.\n",
    "            Custom search algorithms may ignore this.\n",
    "        trial_resources (dict): Machine resources to allocate per trial,\n",
    "            e.g. ``{\"cpu\": 64, \"gpu\": 8}``. Note that GPUs will not be\n",
    "            assigned unless you specify them here. Defaults to 1 CPU and 0\n",
    "            GPUs in ``Trainable.default_resource_request()``.\n",
    "        ...\n",
    "```\n",
    "\n",
    "First, **set the stopping criteria to stop when `mean_accuracy` passes `0.95` (step 1)**.\n",
    "\n",
    "\n",
    "We also want to designate a search space. **Randomly search for learning rate (`lr`) between 0.001 to 0.1, and do a grid search over `momentum` for `[0.2, 0.4, 0.6]`  (step 2)**(https://ray.readthedocs.io/en/latest/tune-usage.html#tune-search-space-default).\n",
    "\n",
    "You can use `tune.grid_search` to specify an axis of a grid search. By default, Tune also supports sampling parameters from user-specified lambda functions, which can be used independently or in combination with grid search.\n",
    "\n",
    "The following example shows grid search over two nested parameters combined with random sampling from a lambda functions, generating 9 different trials. \n",
    "\n",
    "```python\n",
    "config={\n",
    "    \"alpha\": lambda spec: np.random.uniform(100),\n",
    "    \"nn_layers\": [\n",
    "         tune.grid_search([16, 64, 256]),\n",
    "         tune.grid_search([16, 64, 256]),\n",
    "    ],\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = tune.Experiment(\n",
    "    \"experiment_name\",\n",
    "    run=train_mnist_tune,\n",
    "    trial_resources={\"cpu\": 4},\n",
    "    stop={},  # TODO: step 1\n",
    "    config={}  # TODO: step 2\n",
    ")\n",
    "\n",
    "assert configuration.spec.get(\"stop\", {}).get(\"mean_accuracy\") == 0.95\n",
    "assert \"grid_search\" in configuration.spec.get(\"config\", {}).get(\"momentum\", {})\n",
    "assert \"lr\" in configuration.spec.get(\"config\", {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run our experiment with a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = tune.run_experiments(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best result is\", get_best_result(trials, metric=\"mean_accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Try using a scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Tune schedules trials in serial order with the `FIFOScheduler class`. However, you can also specify a custom scheduling algorithm that can early stop trials or perturb parameters. Let's use a state of the art algorithm, `HyperBand` to scale up and accelerate our training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise has two parts.\n",
    "\n",
    "First, **modify your previous configuration in the cell below to sample the search space 10 times (step 1)**. (https://ray.readthedocs.io/en/latest/tune-usage.html#sampling-multiple-times). An extended version of the `Experiment` documentation is shown below. Note that you should expect a total of 30 trials, due to the usage of `grid_search`.\n",
    "\n",
    "```python\n",
    "class ray.tune.Experiment(name, run, stop=None, config=None, ... ):\n",
    "    \"\"\"Tracks experiment specifications.\n",
    "\n",
    "    Parameters:\n",
    "        name (str): Name of experiment.\n",
    "        run (function|class|str): The algorithm or model to train.\n",
    "            This may refer to the name of a built-on algorithm\n",
    "            (e.g. RLLib's DQN or PPO), a user-defined trainable\n",
    "            function or class, or the string identifier of a\n",
    "            trainable function or class registered in the tune registry.\n",
    "        stop (dict): The stopping criteria. The keys may be any field in\n",
    "            the return result of 'train()', whichever is reached first.\n",
    "            Defaults to empty dict.\n",
    "        config (dict): Algorithm-specific configuration for Tune variant\n",
    "            generation (e.g. env, hyperparams). Defaults to empty dict.\n",
    "            Custom search algorithms may ignore this.\n",
    "        trial_resources (dict): Machine resources to allocate per trial,\n",
    "            e.g. ``{\"cpu\": 64, \"gpu\": 8}``. Note that GPUs will not be\n",
    "            assigned unless you specify them here. Defaults to 1 CPU and 0\n",
    "            GPUs in ``Trainable.default_resource_request()``.\n",
    "        num_samples (int): Number of times to sample from the\n",
    "            hyperparameter space. Defaults to 1. If `grid_search` is\n",
    "            provided as an argument, the grid will be repeated\n",
    "            `num_samples` of times.\n",
    "        ...\n",
    "```\n",
    "Next, **create an Asynchronous HyperBand Scheduler (step 2)** (https://ray.readthedocs.io/en/latest/tune-schedulers.html#asynchronous-hyperband). The documentation is shown below. \n",
    "\n",
    "\n",
    "\n",
    "Be sure to set the `time_attr` to `training_iteration` and `reward_attr` to `mean_accuracy`.\n",
    "\n",
    "```python\n",
    "class AsyncHyperBandScheduler(FIFOScheduler):\n",
    "    \"\"\"This provides HyperBand functionality to your search.\n",
    "    \n",
    "    Hyperband is an algorithm that focuses on speeding up \n",
    "    random search through adaptive resource allocation and early-stopping.\n",
    "\n",
    "    See https://openreview.net/forum?id=S1Y7OOlRZ\n",
    "\n",
    "    Args:\n",
    "        time_attr (str): A training result attr to use for comparing time.\n",
    "            Note that you can pass in something non-temporal such as\n",
    "            `training_iteration` as a measure of progress, the only requirement\n",
    "            is that the attribute should increase monotonically.\n",
    "        reward_attr (str): The training result objective value attribute. As\n",
    "            with `time_attr`, this may refer to any objective value. Stopping\n",
    "            procedures will use this attribute.\n",
    "        ...\n",
    "        \n",
    "    Examples:\n",
    "        >>> hyperband = AsyncHyperBandScheduler(\n",
    "        >>>     time_attr='training_iteration',\n",
    "        >>>     reward_attr='mean_accuracy')\n",
    "    \"\"\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "## TODO: Create an Asynchronous HyperBand Scheduler\n",
    "hyperband = None\n",
    "\n",
    "configuration.spec[\"num_samples\"] = None  # TODO: set this to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the previous configuration, pass in the HyperBand scheduler to `run_experiments`.\n",
    "\n",
    "Recall that the `run_experiments` API is:\n",
    "```python\n",
    "def run_experiments(experiments=None,\n",
    "                    search_alg=None,\n",
    "                    scheduler=None,\n",
    "                    ...):\n",
    "    \"\"\"Runs and blocks until all trials finish.\n",
    "\n",
    "    Args:\n",
    "        experiments (Experiment | list | dict): Experiments to run. Will be\n",
    "            passed to `search_alg` via `add_configurations`.\n",
    "        search_alg (SearchAlgorithm): Search Algorithm. Defaults to\n",
    "            BasicVariantGenerator.\n",
    "        scheduler (TrialScheduler): Scheduler for executing\n",
    "            the experiment. Choose among FIFO (default), MedianStopping,\n",
    "            AsyncHyperBand, and HyperBand.\n",
    "        ...\n",
    "    \n",
    "    Returns:\n",
    "        List of Trial objects, holding data for each executed trial.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Call `run_experiments` with the correct arguments\n",
    "trials = tune.run_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the best model from your search process, and check its validation accuracy compared to the first model we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = get_best_model(make_model, trials, metric=\"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data, validation_labels = load_validation()\n",
    "best_model.evaluate(validation_data, validation_labels)\n",
    "\n",
    "first_model.evaluate(validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out your model on some manual inputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, write a digit into the canvas below. This will automatically load your input into the variable `final_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(open(\"input_final.html\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_input = prepare_data(final_data)\n",
    "best = best_model.predict(manual_input).argmax()\n",
    "first = first_model.predict(manual_input).argmax()\n",
    "\n",
    "print(\"Best model got {}, first model got {}\".format(best, first))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Try using a search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune is an execution layer, so we can combine powerful optimizers such as HyperOpt (https://github.com/hyperopt/hyperopt) with state-of-the-art algorithms such as HyperBand without modifying any model training code.\n",
    "\n",
    "The documentation to doing this is here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "1. Create a HyperOptSearch object and run an experiment combining both the previously created `hyperband` scheduler and this Search algorithm. Use the given search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from ray.tune.suggest import HyperOptSearch\n",
    "\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.uniform(\"lr\", 0.001, 0.1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"hidden\": hp.choice(\"hidden\", np.arange(16, 256, dtype=int)),\n",
    "    \"dropout1\": hp.uniform(\"dropout1\", 0.2, 0.8),\n",
    "}\n",
    "\n",
    "## TODO: CREATE A HyperOptObject\n",
    "hyperopt_search = HyperOptSearch(space, reward_attr=\"mean_accuracy\")\n",
    "\n",
    "## TODO: Pass in the object to Tune.\n",
    "good_results = tune.run_experiments(\n",
    "    configuration, search_alg=hyperopt_search, scheduler=hyperband)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to compare your best mdodel here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
